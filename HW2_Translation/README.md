### Домашнее задание машинного перевода

Мы будем с вами честными - мы очень сильно переоценили свои возможности, когда взялись за машинный перевод, даже несмотря на имеющиеся самоучители по пайторчу и сег2сегу. Очень долго боролись с самым первым заданием, чтобы понять, как там делается вывод, на чем тренировать, как обрабатывать предложения и так далее. Каждая ошибка в непонимании кода стоила нам 2 часа времени - именно столько обучался алгоритм, если не ломался сразу (так, мы однажды случайно сделали "перевод" с индексов французских слов на немецкий. Представьте нашу реакцию на выводе через 2 часа обучения).

Собрали здесь все наши колабы, потому что неудобно все пробы было делать в одном. В итоге имеем:
1. Первое задание с прямым сорсом: https://colab.research.google.com/drive/1O8uu9RF2oAk0G6QdvDWkQaXs6N97sd3C

2. Первое задание с перевернутым сорсом (неудачная попытка улучшить BLUE): https://colab.research.google.com/drive/1ehcqf2uZ2eWFByv5bRRlcIrYSEhNwcJQ

3. (Неудачная) попытка мультиэнкодера: https://colab.research.google.com/drive/1ycheEtpB9EMPsgmRZXZ4CAmGs0nzTSTX
Неудачной она оказалась, на самом деле, потому что мы не успели разобраться с тем, как давать на вход тензоры сразу от нескольких предложений. Получили эмбеддинги даже в энкодере, но уже в трейне сломались. Сейчас пытаемся разобраться, но опаздываем со сдачей и параллельно пытаемся сделать вывод из трансформера.
По сути, просто нужно переписать только функцию трейна, итерационного трейна и evaluate, добавив туда тензоры ото всех языков, но мы пытались, и почему-то никак не можем разобраться с размерностью вектора на вход. Сейчас колаб с мультиэнкодером выглядит позорно, но хотя бы ломается только на итертрейне, поэтому нам не так стыдно его вам показывать - раньше он ломался аж на классе Lang в самом начале, представляете?
Есть два варианта борьбы с тензорами, которые нам видятся (мы частично попробовали оба):
a) Брать тензоры от каждого языка, конкатенировать их и подавать как ОДИН БОЛЬШОЙ тензор на вход трейну. Пока что эта идея сломалась на моменте эмбеддингов - не получается передавать их по отдельности, потому что идет проблема как раз в трейне. Исправляемо, конечно.
b) Подавать как три разных тензора. Переписать функцию трейна так, чтобы он не боялся нескольких тензоров.

4. Попытка использовать Transformer с улучшением и выводом картинок:

5. NMT с эмбеддингами (еще тренируется, очень тяжелый): https://colab.research.google.com/drive/1JIZhsQH7JvIRdLuA7b1p88xwCg-CGv7r
